#!/usr/bin/env python3
"""
–°–µ—Ç–µ–≤—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –ø—Ä–æ–∫—Å–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∏
"""

import aiohttp
import asyncio
import requests
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse, urljoin
import time
from pathlib import Path
from .logger import setup_logger


class NetworkUtils:
    """–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Å–µ—Ç–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = setup_logger("network_utils")
        self.session = None
    
    async def check_internet_connection(self, timeout: int = 10) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        
        Args:
            timeout: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            bool: –ï—Å—Ç—å –ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
        """
        test_urls = [
            "https://www.google.com",
            "https://www.cloudflare.com",
            "https://www.yandex.ru"
        ]
        
        for url in test_urls:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=timeout) as response:
                        if response.status == 200:
                            self.logger.info("‚úÖ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ")
                            return True
            except Exception as e:
                self.logger.debug(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ {url}: {e}")
                continue
        
        self.logger.error("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ")
        return False
    
    async def check_site_availability(self, url: str, timeout: int = 15) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–∞–π—Ç–∞
        
        Args:
            url: URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            timeout: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏
        """
        start_time = time.time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=timeout) as response:
                    response_time = time.time() - start_time
                    
                    result = {
                        'url': url,
                        'available': True,
                        'status_code': response.status,
                        'response_time': round(response_time, 2),
                        'content_type': response.headers.get('content-type', ''),
                        'server': response.headers.get('server', ''),
                        'size_bytes': int(response.headers.get('content-length', 0))
                    }
                    
                    self.logger.info(f"‚úÖ –°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω: {url} ({response.status})")
                    return result
                    
        except asyncio.TimeoutError:
            self.logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {url}")
            return {
                'url': url,
                'available': False,
                'error': 'timeout',
                'response_time': timeout
            }
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ {url}: {e}")
            return {
                'url': url,
                'available': False,
                'error': str(e),
                'response_time': round(time.time() - start_time, 2)
            }
    
    async def download_file(self, url: str, save_path: str, timeout: int = 30) -> bool:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
        
        Args:
            url: URL —Ñ–∞–π–ª–∞
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            timeout: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=timeout) as response:
                    if response.status == 200:
                        content = await response.read()
                        
                        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
                        
                        with open(save_path, 'wb') as f:
                            f.write(content)
                        
                        self.logger.info(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {url} -> {save_path}")
                        return True
                    else:
                        self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ HTTP {response.status} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}")
                        return False
                        
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return False
    
    async def test_proxy(self, proxy_url: str, test_url: str = "https://httpbin.org/ip") -> Dict[str, Any]:
        """
        –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞
        
        Args:
            proxy_url: URL –ø—Ä–æ–∫—Å–∏ (http://ip:port –∏–ª–∏ socks5://ip:port)
            test_url: URL –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞
        """
        start_time = time.time()
        
        try:
            connector = aiohttp.TCPConnector()
            timeout = aiohttp.ClientTimeout(total=15)
            
            async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
                async with session.get(test_url, proxy=proxy_url) as response:
                    response_time = time.time() - start_time
                    data = await response.json()
                    
                    return {
                        'proxy': proxy_url,
                        'working': True,
                        'response_time': round(response_time, 2),
                        'your_ip': data.get('origin', ''),
                        'status_code': response.status
                    }
                    
        except Exception as e:
            return {
                'proxy': proxy_url,
                'working': False,
                'error': str(e),
                'response_time': round(time.time() - start_time, 2)
            }
    
    async def batch_test_proxies(self, proxies: List[str], max_concurrent: int = 5) -> List[Dict[str, Any]]:
        """
        –ú–∞—Å—Å–æ–≤–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–æ–≤
        
        Args:
            proxies: –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏
            max_concurrent: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
            
        Returns:
            List: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.logger.info(f"üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(proxies)} –ø—Ä–æ–∫—Å–∏...")
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def test_with_semaphore(proxy):
            async with semaphore:
                return await self.test_proxy(proxy)
        
        tasks = [test_with_semaphore(proxy) for proxy in proxies]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏
        working_proxies = [r for r in results if isinstance(r, dict) and r.get('working')]
        
        self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏: {len(working_proxies)}/{len(proxies)}")
        return working_proxies
    
    def validate_url(self, url: str) -> Tuple[bool, str]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è URL
        
        Args:
            url: URL –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            Tuple: (–í–∞–ª–∏–¥–µ–Ω –ª–∏, –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ)
        """
        try:
            result = urlparse(url)
            
            if not all([result.scheme, result.netloc]):
                return False, "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç URL"
            
            if result.scheme not in ['http', 'https']:
                return False, "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ HTTP –∏ HTTPS"
            
            return True, "URL –≤–∞–ª–∏–¥–µ–Ω"
            
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}"
    
    async def get_redirect_history(self, url: str, max_redirects: int = 10) -> List[Dict[str, str]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤
        
        Args:
            url: –ò—Å—Ö–æ–¥–Ω—ã–π URL
            max_redirects: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤
            
        Returns:
            List: –ò—Å—Ç–æ—Ä–∏—è —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤
        """
        redirects = []
        current_url = url
        
        for i in range(max_redirects):
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(current_url, allow_redirects=False) as response:
                        
                        redirect_info = {
                            'url': current_url,
                            'status_code': response.status,
                            'location': response.headers.get('location', '')
                        }
                        redirects.append(redirect_info)
                        
                        if response.status in [301, 302, 303, 307, 308]:
                            current_url = urljoin(current_url, response.headers.get('location'))
                        else:
                            break
                            
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞: {e}")
                break
        
        return redirects
    
    def get_domain_info(self, url: str) -> Dict[str, str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–æ–º–µ–Ω–µ
        
        Args:
            url: URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–º–µ–Ω–µ
        """
        try:
            parsed = urlparse(url)
            
            return {
                'domain': parsed.netloc,
                'subdomain': '.'.join(parsed.netloc.split('.')[:-2]),
                'tld': '.'.join(parsed.netloc.split('.')[-2:]),
                'scheme': parsed.scheme,
                'path': parsed.path,
                'full_domain': parsed.netloc
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–º–µ–Ω–∞ {url}: {e}")
            return {}
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Ç–µ–≤—ã—Ö —Å–µ—Å—Å–∏–π"""
        if self.session:
            await self.session.close()
