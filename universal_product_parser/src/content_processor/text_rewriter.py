#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
"""

import re
from typing import Dict, List, Optional, Tuple, Any
from .nlp_engine import NlpEngine
from .synonym_manager import SynonymManager
from .content_validator import ContentValidator
from ..utils.logger import setup_logger
from ..utils.error_handler import retry_on_failure


class TextRewriter:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–º—ã—Å–ª–∞"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = setup_logger("text_rewriter")
        self.nlp_engine = NlpEngine()
        self.synonym_manager = SynonymManager()
        self.validator = ContentValidator()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è
        self.rewrite_settings = {
            'synonym_replacement_rate': 0.7,
            'sentence_reorder_rate': 0.5,
            'structure_change_rate': 0.8,
            'preserve_technical_terms': True,
            'min_meaning_preservation': 0.8
        }
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        if 'content_rewriting' in self.config:
            self.rewrite_settings.update(self.config['content_rewriting'])
    
    @retry_on_failure(max_retries=2)
    def rewrite_description(self, original_text: str, product_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–º—ã—Å–ª–∞
        
        Args:
            original_text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è
            product_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–≤–∞—Ä–∞ (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏ —Ç.–¥.)
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è
        """
        if not original_text or not isinstance(original_text, str):
            return {
                'original': original_text,
                'rewritten': original_text,
                'success': False,
                'error': 'Invalid input text'
            }
        
        self.logger.info(f"üìù –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (–¥–ª–∏–Ω–∞: {len(original_text)})")
        
        try:
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
            cleaned_text = self._preprocess_text(original_text)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            preserved_terms = self._extract_preserved_terms(cleaned_text, product_context)
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é NLP
            analyzed_text = self.nlp_engine.analyze_text(cleaned_text)
            
            # –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            rewritten_text = self._rewrite_with_nlp(analyzed_text, preserved_terms)
            
            # –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞
            final_text = self._postprocess_text(rewritten_text, preserved_terms)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            validation_result = self.validator.validate_rewriting(
                original_text, final_text, self.rewrite_settings['min_meaning_preservation']
            )
            
            result = {
                'original': original_text,
                'rewritten': final_text,
                'success': validation_result['is_valid'],
                'preserved_terms': preserved_terms,
                'validation': validation_result,
                'changes_made': self._calculate_changes(original_text, final_text)
            }
            
            if validation_result['is_valid']:
                self.logger.info("‚úÖ –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω")
            else:
                self.logger.warning("‚ö†Ô∏è  –¢–µ–∫—Å—Ç –ø–µ—Ä–µ–ø–∏—Å–∞–Ω, –Ω–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞")
            
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
            return {
                'original': original_text,
                'rewritten': original_text,
                'success': False,
                'error': str(e)
            }
    
    def _preprocess_text(self, text: str) -> str:
        """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤
        text = re.sub(r'\s+', ' ', text.strip())
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        text = re.sub(r'\.{2,}', '...', text)
        text = re.sub(r'!{2,}', '!', text)
        text = re.sub(r'\?{2,}', '?', text)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–∫—Ä–æ–º–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏)
        text = re.sub(r'[^\w\s\.\,\!\?\-\:\(\)]', '', text)
        
        return text
    
    def _extract_preserved_terms(self, text: str, product_context: Dict[str, Any]) -> Dict[str, List[str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        preserved = {
            'technical_specs': [],
            'brands': [],
            'models': [],
            'measurements': [],
            'materials': []
        }
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if product_context and 'characteristics' in product_context:
            chars = product_context['characteristics']
            for key, value in chars.items():
                if isinstance(value, (int, float)):
                    preserved['technical_specs'].append(f"{key}: {value}")
                elif isinstance(value, str) and any(unit in value.lower() for unit in ['mm', 'cm', 'kg', 'g', 'l', 'ml']):
                    preserved['measurements'].append(f"{key} {value}")
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π –∏–∑ —Ç–µ–∫—Å—Ç–∞
        brands_models = self.nlp_engine.extract_brands_and_models(text)
        preserved['brands'].extend(brands_models.get('brands', []))
        preserved['models'].extend(brands_models.get('models', []))
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞
        tech_terms = self.nlp_engine.extract_technical_terms(text)
        preserved['technical_specs'].extend(tech_terms)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        for key in preserved:
            preserved[key] = list(set(preserved[key]))
        
        return preserved
    
    def _rewrite_with_nlp(self, analyzed_text: Dict[str, Any], preserved_terms: Dict[str, List[str]]) -> str:
        """–ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º NLP"""
        sentences = analyzed_text.get('sentences', [])
        
        if not sentences:
            return analyzed_text.get('original_text', '')
        
        rewritten_sentences = []
        
        for sentence in sentences:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –≤–∞–∂–Ω—ã–º–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏
            if self._contains_preserved_terms(sentence['text'], preserved_terms):
                rewritten_sentences.append(sentence['text'])
                continue
            
            # –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            rewritten_sentence = self._rewrite_sentence(sentence, preserved_terms)
            rewritten_sentences.append(rewritten_sentence)
        
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (—Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é)
        if len(rewritten_sentences) > 1 and self._should_reorder():
            rewritten_sentences = self._reorder_sentences(rewritten_sentences)
        
        return ' '.join(rewritten_sentences)
    
    def _rewrite_sentence(self, sentence: Dict[str, Any], preserved_terms: Dict[str, List[str]]) -> str:
        """–ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        original_sentence = sentence['text']
        
        # –†–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è
        methods = [
            self._replace_with_synonyms,
            self._change_sentence_structure,
            self._paraphrase_sentence
        ]
        
        # –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–ª–∏–Ω—ã –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        if len(sentence['tokens']) < 5:
            # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è - –ø—Ä–æ—Å—Ç–∞—è –∑–∞–º–µ–Ω–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
            return self._replace_with_synonyms(original_sentence, preserved_terms)
        else:
            # –î–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è - –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤
            method = self._choose_rewrite_method(sentence)
            return method(original_sentence, preserved_terms)
    
    def _replace_with_synonyms(self, sentence: str, preserved_terms: Dict[str, List[str]]) -> str:
        """–ó–∞–º–µ–Ω–∞ —Å–ª–æ–≤ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏"""
        words = sentence.split()
        rewritten_words = []
        
        for word in words:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            if self._is_preserved_term(word, preserved_terms):
                rewritten_words.append(word)
                continue
            
            # –ó–∞–º–µ–Ω–∞ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
            if self._should_replace_word():
                synonym = self.synonym_manager.get_synonym(word, context=sentence)
                rewritten_words.append(synonym if synonym else word)
            else:
                rewritten_words.append(word)
        
        return ' '.join(rewritten_words)
    
    def _change_sentence_structure(self, sentence: str, preserved_terms: Dict[str, List[str]]) -> str:
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º NLP –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        return self.nlp_engine.restructure_sentence(sentence, preserved_terms)
    
    def _paraphrase_sentence(self, sentence: str, preserved_terms: Dict[str, List[str]]) -> str:
        """–ü–∞—Ä–∞—Ñ—Ä–∞–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã –ø–∞—Ä–∞—Ñ—Ä–∞–∑–∞
        return self.nlp_engine.paraphrase_sentence(sentence, preserved_terms)
    
    def _contains_preserved_terms(self, text: str, preserved_terms: Dict[str, List[str]]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã"""
        text_lower = text.lower()
        
        for category, terms in preserved_terms.items():
            for term in terms:
                if term.lower() in text_lower:
                    return True
        
        return False
    
    def _is_preserved_term(self, word: str, preserved_terms: Dict[str, List[str]]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º —Ç–µ—Ä–º–∏–Ω–æ–º"""
        word_clean = re.sub(r'[^\w]', '', word.lower())
        
        for category, terms in preserved_terms.items():
            for term in terms:
                term_clean = re.sub(r'[^\w]', '', term.lower())
                if word_clean == term_clean:
                    return True
        
        return False
    
    def _should_replace_word(self) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–º–µ–Ω—è—Ç—å —Å–ª–æ–≤–æ"""
        import random
        return random.random() < self.rewrite_settings['synonym_replacement_rate']
    
    def _should_reorder(self) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –∏–∑–º–µ–Ω—è—Ç—å –ø–æ—Ä—è–¥–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"""
        import random
        return random.random() < self.rewrite_settings['sentence_reorder_rate']
    
    def _choose_rewrite_method(self, sentence: Dict[str, Any]) -> callable:
        """–í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        methods = [
            (self._replace_with_synonyms, 0.4),
            (self._change_sentence_structure, 0.4),
            (self._paraphrase_sentence, 0.2)
        ]
        
        import random
        rand_val = random.random()
        cumulative = 0
        
        for method, probability in methods:
            cumulative += probability
            if rand_val <= cumulative:
                return method
        
        return self._replace_with_synonyms
    
    def _reorder_sentences(self, sentences: List[str]) -> List[str]:
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"""
        if len(sentences) <= 1:
            return sentences
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ä–µ–≤–µ—Ä—Å –∏–ª–∏ —Å–ª—É—á–∞–π–Ω–æ–µ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ
        import random
        if random.random() < 0.5:
            return list(reversed(sentences))
        else:
            shuffled = sentences.copy()
            random.shuffle(shuffled)
            return shuffled
    
    def _postprocess_text(self, text: str, preserved_terms: Dict[str, List[str]]) -> str:
        """–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã
        for category, terms in preserved_terms.items():
            for term in terms:
                # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
                if term not in text:
                    # TODO: –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
                    pass
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        text = self.nlp_engine.correct_grammar(text)
        
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ç–µ–∫—Å—Ç –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π
        text = text.strip()
        if text and not text[-1] in '.!?':
            text += '.'
        
        return text
    
    def _calculate_changes(self, original: str, rewritten: str) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        from difflib import SequenceMatcher
        
        similarity = SequenceMatcher(None, original, rewritten).ratio()
        
        original_words = original.split()
        rewritten_words = rewritten.split()
        
        return {
            'similarity_score': similarity,
            'original_length': len(original),
            'rewritten_length': len(rewritten),
            'original_word_count': len(original_words),
            'rewritten_word_count': len(rewritten_words),
            'change_ratio': 1 - similarity
        }
    
    def batch_rewrite(self, texts: List[str], product_contexts: List[Dict] = None) -> List[Dict[str, Any]]:
        """
        –ü–∞–∫–µ—Ç–Ω–æ–µ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è
            product_contexts: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
            
        Returns:
            List: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        """
        results = []
        
        for i, text in enumerate(texts):
            context = product_contexts[i] if product_contexts and i < len(product_contexts) else None
            result = self.rewrite_description(text, context)
            results.append(result)
        
        return results
