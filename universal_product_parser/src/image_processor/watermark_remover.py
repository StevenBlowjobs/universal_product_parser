#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è 100% —É–¥–∞–ª–µ–Ω–∏—è –≤–æ—Ç–µ—Ä–º–∞—Ä–æ–∫ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤
"""

import cv2
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
from .models.watermark_detector import WatermarkDetector
from ..utils.logger import setup_logger
from ..utils.error_handler import retry_on_failure


class WatermarkRemover:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É–¥–∞–ª–∏—Ç–µ–ª—å –≤–æ—Ç–µ—Ä–º–∞—Ä–æ–∫ —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π 100% –∫–∞—á–µ—Å—Ç–≤–∞"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = setup_logger("watermark_remover")
        self.detector = WatermarkDetector()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_settings = {
            'detection_confidence': 0.8,
            'removal_aggressiveness': 'aggressive',
            'max_repair_attempts': 3,
            'preserve_image_quality': True
        }
        
        if 'image_processing' in self.config:
            self.processing_settings.update(self.config['image_processing'])
    
    @retry_on_failure(max_retries=2)
    def remove_watermark(self, image_path: str, output_path: str = None) -> Dict[str, Any]:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        self.logger.info(f"üñºÔ∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_path}")
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = self._load_image(image_path)
            if image is None:
                return {
                    'success': False,
                    'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
                    'original_path': image_path
                }
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏
            detection_result = self.detector.detect_watermarks(image)
            
            if not detection_result['watermarks_found']:
                self.logger.info("‚úÖ –í–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
                return {
                    'success': True,
                    'watermarks_removed': 0,
                    'message': '–í–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã',
                    'original_path': image_path,
                    'output_path': image_path
                }
            
            self.logger.info(f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≤–æ—Ç–µ—Ä–º–∞—Ä–æ–∫: {len(detection_result['watermarks'])}")
            
            # –ü–æ—ç—Ç–∞–ø–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏
            processed_image = image.copy()
            removal_stats = []
            
            for i, watermark in enumerate(detection_result['watermarks']):
                self.logger.info(f"üîß –£–¥–∞–ª–µ–Ω–∏–µ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ {i+1}/{len(detection_result['watermarks'])}")
                
                removal_result = self._remove_single_watermark(
                    processed_image, watermark, attempt=1
                )
                
                if removal_result['success']:
                    processed_image = removal_result['processed_image']
                    removal_stats.append({
                        'watermark_id': i,
                        'type': watermark['type'],
                        'confidence': watermark['confidence'],
                        'method_used': removal_result['method_used']
                    })
                else:
                    self.logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤–æ—Ç–µ—Ä–º–∞—Ä–∫—É {i+1}")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            validation_result = self._validate_removal(image, processed_image, detection_result)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if output_path:
                save_success = self._save_image(processed_image, output_path)
            else:
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                original_path = Path(image_path)
                output_path = str(original_path.parent / f"{original_path.stem}_no_watermark{original_path.suffix}")
                save_success = self._save_image(processed_image, output_path)
            
            result = {
                'success': validation_result['is_valid'] and save_success,
                'watermarks_detected': len(detection_result['watermarks']),
                'watermarks_removed': len(removal_stats),
                'removal_stats': removal_stats,
                'validation': validation_result,
                'original_path': image_path,
                'output_path': output_path if save_success else None,
                'quality_metrics': self._calculate_quality_metrics(image, processed_image)
            }
            
            if result['success']:
                self.logger.info(f"‚úÖ –í–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω—ã: {output_path}")
            else:
                self.logger.warning(f"‚ö†Ô∏è  –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏: {output_path}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏: {e}")
            return {
                'success': False,
                'error': str(e),
                'original_path': image_path
            }
    
    def _load_image(self, image_path: str) -> Optional[np.ndarray]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
                return None
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            return image_rgb
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return None
    
    def _remove_single_watermark(self, image: np.ndarray, watermark: Dict[str, Any], 
                               attempt: int = 1) -> Dict[str, Any]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–π –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏"""
        methods = [
            self._inpaint_watermark,
            self._texture_synthesis,
            self._patch_based_removal,
            self._deep_learning_removal
        ]
        
        # –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏
        method = self._select_removal_method(watermark)
        processed_image = image.copy()
        
        try:
            result = method(processed_image, watermark)
            
            if result['success']:
                return {
                    'success': True,
                    'processed_image': result['processed_image'],
                    'method_used': method.__name__
                }
            else:
                # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –º–µ—Ç–æ–¥
                if attempt < self.processing_settings['max_repair_attempts']:
                    return self._remove_single_watermark(
                        image, watermark, attempt + 1
                    )
                else:
                    return {
                        'success': False,
                        'error': '–í—Å–µ –º–µ—Ç–æ–¥—ã —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏',
                        'method_used': method.__name__
                    }
                    
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–µ—Ç–æ–¥–µ {method.__name__}: {e}")
            return {
                'success': False,
                'error': str(e),
                'method_used': method.__name__
            }
    
    def _select_removal_method(self, watermark: Dict[str, Any]) -> callable:
        """–í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ —É–¥–∞–ª–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏"""
        watermark_type = watermark.get('type', 'unknown')
        
        method_mapping = {
            'text_logo': self._inpaint_watermark,
            'transparent_logo': self._texture_synthesis,
            'corner_stamp': self._patch_based_removal,
            'diagonal_text': self._deep_learning_removal,
            'background_pattern': self._texture_synthesis
        }
        
        return method_mapping.get(watermark_type, self._inpaint_watermark)
    
    def _inpaint_watermark(self, image: np.ndarray, watermark: Dict[str, Any]) -> Dict[str, Any]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ –º–µ—Ç–æ–¥–æ–º inpainting"""
        try:
            mask = watermark.get('mask')
            if mask is None:
                return {'success': False, 'error': '–ù–µ—Ç –º–∞—Å–∫–∏ –¥–ª—è inpainting'}
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–∞—Å–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            if len(mask.shape) == 3:
                mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)
            
            # Inpainting —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
            methods = [
                (cv2.INPAINT_TELEA, 'telea'),
                (cv2.INPAINT_NS, 'ns')
            ]
            
            best_result = None
            best_quality = 0
            
            for method_code, method_name in methods:
                inpainted = cv2.inpaint(image, mask, 3, method_code)
                
                # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                quality = self._assess_inpainting_quality(image, inpainted, mask)
                
                if quality > best_quality:
                    best_quality = quality
                    best_result = inpainted
            
            return {
                'success': True,
                'processed_image': best_result,
                'quality_score': best_quality
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _texture_synthesis(self, image: np.ndarray, watermark: Dict[str, Any]) -> Dict[str, Any]:
        """–£–¥–∞–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–∏–Ω—Ç–µ–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã"""
        try:
            mask = watermark.get('mask')
            bbox = watermark.get('bbox')
            
            if bbox is None:
                return {'success': False, 'error': '–ù–µ—Ç bounding box –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã'}
            
            x, y, w, h = bbox
            
            # –í—ã–¥–µ–ª–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –≤–æ–∫—Ä—É–≥ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ –¥–ª—è –∑–∞–±–æ—Ä–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã
            padding = 20
            sample_x = max(0, x - padding)
            sample_y = max(0, y - padding)
            sample_w = min(image.shape[1] - sample_x, w + 2 * padding)
            sample_h = min(image.shape[0] - sample_y, h + 2 * padding)
            
            sample_region = image[sample_y:sample_y+sample_h, sample_x:sample_x+sample_w]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ç—á–∞ –¥–ª—è –∑–∞–º–µ–Ω—ã
            patch = self._generate_texture_patch(sample_region, (h, w))
            
            # –ó–∞–º–µ–Ω–∞ –æ–±–ª–∞—Å—Ç–∏ —Å –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–æ–π
            result_image = image.copy()
            result_image[y:y+h, x:x+w] = patch
            
            return {
                'success': True,
                'processed_image': result_image
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _patch_based_removal(self, image: np.ndarray, watermark: Dict[str, Any]) -> Dict[str, Any]:
        """–£–¥–∞–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –∏ –∑–∞–º–µ–Ω—É –ø–∞—Ç—á–µ–π"""
        try:
            bbox = watermark.get('bbox')
            if bbox is None:
                return {'success': False, 'error': '–ù–µ—Ç bounding box –¥–ª—è patch-based —É–¥–∞–ª–µ–Ω–∏—è'}
            
            x, y, w, h = bbox
            
            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—á–µ–π –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
            similar_patches = self._find_similar_patches(image, (x, y, w, h))
            
            if not similar_patches:
                return {'success': False, 'error': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–∞—Ç—á–µ–π –¥–ª—è –∑–∞–º–µ–Ω—ã'}
            
            # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø–∞—Ç—á–∞
            best_patch = self._select_best_patch(image, similar_patches, (x, y, w, h))
            
            # –ó–∞–º–µ–Ω–∞ –æ–±–ª–∞—Å—Ç–∏
            result_image = image.copy()
            result_image[y:y+h, x:x+w] = best_patch
            
            return {
                'success': True,
                'processed_image': result_image
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _deep_learning_removal(self, image: np.ndarray, watermark: Dict[str, Any]) -> Dict[str, Any]:
        """–£–¥–∞–ª–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
        # TODO: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π GAN –º–æ–¥–µ–ª—å—é –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤–æ—Ç–µ—Ä–º–∞—Ä–æ–∫
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –º–µ—Ç–æ–¥–æ–≤
        
        combined_result = self._inpaint_watermark(image, watermark)
        if combined_result['success']:
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞
            processed = self._post_process_removal(combined_result['processed_image'], watermark)
            combined_result['processed_image'] = processed
        
        return combined_result
    
    def _generate_texture_patch(self, sample_region: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç—É—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µÊ†∑Êú¨Âå∫Âüü"""
        target_h, target_w = target_size
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ä–µ—Å–∞–π–∑ —Å –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π
        patch = cv2.resize(sample_region, (target_w, target_h), interpolation=cv2.INTER_CUBIC)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        noise = np.random.normal(0, 5, patch.shape).astype(np.uint8)
        patch = cv2.add(patch, noise)
        
        return patch
    
    def _find_similar_patches(self, image: np.ndarray, target_bbox: Tuple[int, int, int, int]) -> List[Tuple[int, int]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—á–µ–π –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        x, y, w, h = target_bbox
        target_patch = image[y:y+h, x:x+w]
        
        similar_patches = []
        stride = 5
        
        for i in range(0, image.shape[0] - h, stride):
            for j in range(0, image.shape[1] - w, stride):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ü–µ–ª–µ–≤—É—é –æ–±–ª–∞—Å—Ç—å –∏ –±–ª–∏–∑–ª–µ–∂–∞—â–∏–µ –æ–±–ª–∞—Å—Ç–∏
                if abs(i - y) < h and abs(j - x) < w:
                    continue
                
                candidate_patch = image[i:i+h, j:j+w]
                similarity = self._calculate_patch_similarity(target_patch, candidate_patch)
                
                if similarity < 0.3:  # –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
                    similar_patches.append((j, i, similarity))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏
        similar_patches.sort(key=lambda x: x[2])
        return [(x, y) for x, y, sim in similar_patches[:10]]  # –¢–æ–ø-10
    
    def _calculate_patch_similarity(self, patch1: np.ndarray, patch2: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è –ø–∞—Ç—á–∞–º–∏"""
        if patch1.shape != patch2.shape:
            return float('inf')
        
        # MSE (Mean Squared Error)
        mse = np.mean((patch1 - patch2) ** 2)
        return mse
    
    def _select_best_patch(self, image: np.ndarray, patches: List[Tuple[int, int]], 
                          target_bbox: Tuple[int, int, int, int]) -> np.ndarray:
        """–í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø–∞—Ç—á–∞ –¥–ª—è –∑–∞–º–µ–Ω—ã"""
        x, y, w, h = target_bbox
        target_patch = image[y:y+h, x:x+w]
        
        best_patch = None
        best_score = float('inf')
        
        for patch_x, patch_y in patches:
            candidate = image[patch_y:patch_y+h, patch_x:patch_x+w]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
            score = self._calculate_replacement_score(target_patch, candidate, image, (x, y), (patch_x, patch_y))
            
            if score < best_score:
                best_score = score
                best_patch = candidate
        
        return best_patch if best_patch is not None else target_patch
    
    def _calculate_replacement_score(self, target: np.ndarray, candidate: np.ndarray,
                                   image: np.ndarray, target_pos: Tuple[int, int], 
                                   candidate_pos: Tuple[int, int]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–º–µ–Ω—ã"""
        # –°—Ö–æ–∂–µ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        content_similarity = self._calculate_patch_similarity(target, candidate)
        
        # –°—Ö–æ–∂–µ—Å—Ç—å —Å –æ–∫—Ä—É–∂–∞—é—â–∏–º–∏ –æ–±–ª–∞—Å—Ç—è–º–∏
        border_similarity = self._calculate_border_similarity(image, target_pos, candidate_pos, target.shape)
        
        return content_similarity + border_similarity
    
    def _calculate_border_similarity(self, image: np.ndarray, pos1: Tuple[int, int], 
                                   pos2: Tuple[int, int], size: Tuple[int, int]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π"""
        h, w = size
        x1, y1 = pos1
        x2, y2 = pos2
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∏–∫—Å–µ–ª–µ–π –≤–æ–∫—Ä—É–≥ –ø–∞—Ç—á–µ–π
        border_score = 0
        border_width = 5
        
        # –í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞
        if y1 > border_width and y2 > border_width:
            top1 = image[y1-border_width:y1, x1:x1+w]
            top2 = image[y2-border_width:y2, x2:x2+w]
            border_score += self._calculate_patch_similarity(top1, top2)
        
        # –ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞
        if y1 + h < image.shape[0] - border_width and y2 + h < image.shape[0] - border_width:
            bottom1 = image[y1+h:y1+h+border_width, x1:x1+w]
            bottom2 = image[y2+h:y2+h+border_width, x2:x2+w]
            border_score += self._calculate_patch_similarity(bottom1, bottom2)
        
        return border_score
    
    def _post_process_removal(self, image: np.ndarray, watermark: Dict[str, Any]) -> np.ndarray:
        """–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏"""
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        processed = image.copy()
        
        # Gaussian blur –¥–ª—è –æ–±–ª–∞—Å—Ç–µ–π —Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏
        if watermark.get('bbox'):
            x, y, w, h = watermark['bbox']
            roi = processed[y:y+h, x:x+w]
            blurred_roi = cv2.GaussianBlur(roi, (3, 3), 0)
            processed[y:y+h, x:x+w] = blurred_roi
        
        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
        processed = self._enhance_histogram(processed)
        
        return processed
    
    def _enhance_histogram(self, image: np.ndarray) -> np.ndarray:
        """–£–ª—É—á—à–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        
        if len(image.shape) == 3:
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            lab[:,:,0] = clahe.apply(lab[:,:,0])
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        else:
            enhanced = clahe.apply(image)
        
        return enhanced
    
    def _assess_inpainting_quality(self, original: np.ndarray, inpainted: np.ndarray, 
                                 mask: np.ndarray) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ inpainting"""
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–Ω–∏—Ü—ã —Ç–æ–ª—å–∫–æ –≤ –æ–±–ª–∞—Å—Ç–∏ –º–∞—Å–∫–∏
        diff = cv2.absdiff(original, inpainted)
        masked_diff = cv2.bitwise_and(diff, diff, mask=mask)
        
        # –ß–µ–º –º–µ–Ω—å—à–µ —Ä–∞–∑–Ω–∏—Ü–∞, —Ç–µ–º –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ
        quality_score = 1.0 - (np.mean(masked_diff) / 255.0)
        return max(0.0, min(1.0, quality_score))
    
    def _validate_removal(self, original: np.ndarray, processed: np.ndarray,
                         detection_result: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–∏—è"""
        # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        new_detection = self.detector.detect_watermarks(processed)
        
        remaining_watermarks = len(new_detection['watermarks'])
        original_watermarks = len(detection_result['watermarks'])
        
        is_valid = remaining_watermarks == 0
        
        return {
            'is_valid': is_valid,
            'original_watermarks': original_watermarks,
            'remaining_watermarks': remaining_watermarks,
            'removal_efficiency': (original_watermarks - remaining_watermarks) / original_watermarks,
            'new_detection_result': new_detection
        }
    
    def _calculate_quality_metrics(self, original: np.ndarray, processed: np.ndarray) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # PSNR (Peak Signal-to-Noise Ratio)
        mse = np.mean((original - processed) ** 2)
        if mse == 0:
            psnr = 100  # –ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å
        else:
            psnr = 20 * np.log10(255.0 / np.sqrt(mse))
        
        # SSIM (Structural Similarity)
        from skimage.metrics import structural_similarity as ssim
        ssim_score = ssim(original, processed, multichannel=True, channel_axis=2)
        
        return {
            'psnr': psnr,
            'ssim': ssim_score,
            'mse': mse,
            'quality_score': (psnr / 50 + ssim_score) / 2  # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        }
    
    def _save_image(self, image: np.ndarray, output_path: str) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ BGR –¥–ª—è OpenCV
            if len(image.shape) == 3:
                image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            else:
                image_bgr = image
            
            success = cv2.imwrite(output_path, image_bgr)
            return success
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return False
    
    def batch_remove_watermarks(self, image_paths: List[str], 
                              output_dir: str = None) -> List[Dict[str, Any]]:
        """
        –ü–∞–∫–µ—Ç–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –≤–æ—Ç–µ—Ä–º–∞—Ä–æ–∫
        
        Args:
            image_paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            List: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        results = []
        
        for image_path in image_paths:
            if output_dir:
                output_path = Path(output_dir) / f"{Path(image_path).stem}_processed{Path(image_path).suffix}"
            else:
                output_path = None
            
            result = self.remove_watermark(image_path, output_path)
            results.append(result)
        
        return results
