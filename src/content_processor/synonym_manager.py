#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è–º–∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ –∑–∞–º–µ–Ω—ã —Å–ª–æ–≤
"""

import json
import re
from typing import Dict, List, Optional, Set, Any
from pathlib import Path
from ..utils.logger import setup_logger
from ..utils.error_handler import retry_on_failure


class SynonymManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∑–∞–≤–∏—Å–∏–º–æ–π –∑–∞–º–µ–Ω—ã —Å–ª–æ–≤"""
    
    def __init__(self, dictionaries_path: str = "data/input/synonym_dictionaries"):
        self.dictionaries_path = Path(dictionaries_path)
        self.logger = setup_logger("synonym_manager")
        self.synonym_dict = {}
        self.technical_terms = set()
        self._load_dictionaries()
    
    def _load_dictionaries(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—â–µ–≥–æ —Å–ª–æ–≤–∞—Ä—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤
            general_path = self.dictionaries_path / "general_synonyms.json"
            if general_path.exists():
                with open(general_path, 'r', encoding='utf-8') as f:
                    self.synonym_dict = json.load(f)
                self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤: {len(self.synonym_dict)} –∑–∞–ø–∏—Å–µ–π")
            else:
                self.logger.warning("‚ö†Ô∏è  –§–∞–π–ª general_synonyms.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
                self._create_default_synonym_dict()
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
            technical_path = self.dictionaries_path / "technical_terms.json"
            if technical_path.exists():
                with open(technical_path, 'r', encoding='utf-8') as f:
                    technical_data = json.load(f)
                    self.technical_terms = set(technical_data.get('preserved_terms', []))
                self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã: {len(self.technical_terms)} —Ç–µ—Ä–º–∏–Ω–æ–≤")
            else:
                self.logger.warning("‚ö†Ô∏è  –§–∞–π–ª technical_terms.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
                self._create_default_technical_terms()
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ª–æ–≤–∞—Ä–µ–π: {e}")
            self._create_default_synonym_dict()
            self._create_default_technical_terms()
    
    def _create_default_synonym_dict(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        self.synonym_dict = {
            "—Ö–æ—Ä–æ—à–∏–π": ["–æ—Ç–ª–∏—á–Ω—ã–π", "–ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–π", "–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π", "–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π"],
            "–ø–ª–æ—Ö–æ–π": ["–Ω–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π", "–Ω–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π", "—Å–ª–∞–±—ã–π"],
            "–∫—Ä–∞—Å–∏–≤—ã–π": ["–ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π", "—ç—Å—Ç–µ—Ç–∏—á–Ω—ã–π", "–∏–∑—è—â–Ω—ã–π"],
            "–±–æ–ª—å—à–æ–π": ["–∫—Ä—É–ø–Ω—ã–π", "–º–∞—Å—à—Ç–∞–±–Ω—ã–π", "–æ–±—à–∏—Ä–Ω—ã–π"],
            "–º–∞–ª–µ–Ω—å–∫–∏–π": ["–Ω–µ–±–æ–ª—å—à–æ–π", "–∫–æ–º–ø–∞–∫—Ç–Ω—ã–π", "–º–∏–Ω–∏–∞—Ç—é—Ä–Ω—ã–π"],
            "–¥–æ—Ä–æ–≥–æ–π": ["—Ü–µ–Ω–Ω—ã–π", "—Å—Ç–æ–∏–º–æ—Å—Ç–Ω—ã–π", "–ø—Ä–µ–º–∏–∞–ª—å–Ω—ã–π"],
            "–¥–µ—à–µ–≤—ã–π": ["—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π", "–±—é–¥–∂–µ—Ç–Ω—ã–π", "–Ω–µ–¥–æ—Ä–æ–≥–æ–π"],
            "–Ω–æ–≤—ã–π": ["—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π", "–∞–∫—Ç—É–∞–ª—å–Ω—ã–π", "—Å–≤–µ–∂–∏–π"],
            "—Å—Ç–∞—Ä—ã–π": ["—É—Å—Ç–∞—Ä–µ–≤—à–∏–π", "–∞—Ä—Ö–∞–∏—á–Ω—ã–π", "–≤–µ—Ç—Ö–∏–π"],
            "–±—ã—Å—Ç—Ä—ã–π": ["—Å–∫–æ—Ä–æ—Å—Ç–Ω–æ–π", "–æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—ã–π", "—à—É—Å—Ç—Ä—ã–π"],
            "–º–µ–¥–ª–µ–Ω–Ω—ã–π": ["–Ω–µ—Ç–æ—Ä–æ–ø–ª–∏–≤—ã–π", "–∑–∞–º–µ–¥–ª–µ–Ω–Ω—ã–π", "—Ä–∞–∑–º–µ—Ä–µ–Ω–Ω—ã–π"],
            "–ª–µ–≥–∫–∏–π": ["–ø—Ä–æ—Å—Ç–æ–π", "–Ω–µ—Ç—Ä—É–¥–Ω—ã–π", "—ç–ª–µ–º–µ–Ω—Ç–∞—Ä–Ω—ã–π"],
            "—Ç—è–∂–µ–ª—ã–π": ["—Å–ª–æ–∂–Ω—ã–π", "–∑–∞—Ç—Ä—É–¥–Ω–∏—Ç–µ–ª—å–Ω—ã–π", "–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω—ã–π"],
            "–≤–∞–∂–Ω—ã–π": ["–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π", "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π", "–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π"],
            "–ø–æ–ª–µ–∑–Ω—ã–π": ["—Ü–µ–Ω–Ω—ã–π", "–ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π", "—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π"],
            "–∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π": ["—É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π", "–∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π", "–ª—é–±–æ–ø—ã—Ç–Ω—ã–π"],
            "–ø–æ–ø—É–ª—è—Ä–Ω—ã–π": ["–≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω—ã–π", "—Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–π", "–∏–∑–≤–µ—Å—Ç–Ω—ã–π"],
            "—É–Ω–∏–∫–∞–ª—å–Ω—ã–π": ["—ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–π", "–Ω–µ–ø–æ–≤—Ç–æ—Ä–∏–º—ã–π", "–æ—Å–æ–±–µ–Ω–Ω—ã–π"],
            "–Ω–∞–¥–µ–∂–Ω—ã–π": ["–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π", "—Å—Ç–∞–±–∏–ª—å–Ω—ã–π", "–ø—Ä–æ—á–Ω—ã–π"],
            "—É–¥–æ–±–Ω—ã–π": ["–∫–æ–º—Ñ–æ—Ä—Ç–Ω—ã–π", "—ç—Ä–≥–æ–Ω–æ–º–∏—á–Ω—ã–π", "–ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π"]
        }
        self.logger.info("‚úÖ –°–æ–∑–¥–∞–Ω —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
    def _create_default_technical_terms(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        self.technical_terms = {
            # –ï–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
            "–º–º", "—Å–º", "–º", "–∫–º", "–≥", "–∫–≥", "–ª", "–º–ª", "–í—Ç", "–∫–í—Ç", 
            "–ì—Ü", "–∫–ì—Ü", "–ú–ì—Ü", "–í", "–ê", "–û–º", "¬∞C", "¬∞F",
            
            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            "–¥–∏–∞–º–µ—Ç—Ä", "–¥–ª–∏–Ω–∞", "—à–∏—Ä–∏–Ω–∞", "–≤—ã—Å–æ—Ç–∞", "–≥–ª—É–±–∏–Ω–∞", "—Ç–æ–ª—â–∏–Ω–∞",
            "–æ–±—ä–µ–º", "–≤–µ—Å", "–º–æ—â–Ω–æ—Å—Ç—å", "–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ", "—Ç–æ–∫", "—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ",
            "—á–∞—Å—Ç–æ—Ç–∞", "—Å–∫–æ—Ä–æ—Å—Ç—å", "–¥–∞–≤–ª–µ–Ω–∏–µ", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
            
            # –ú–∞—Ç–µ—Ä–∏–∞–ª—ã
            "—Å—Ç–∞–ª—å", "–∞–ª—é–º–∏–Ω–∏–π", "–ø–ª–∞—Å—Ç–∏–∫", "–¥–µ—Ä–µ–≤–æ", "—Å—Ç–µ–∫–ª–æ", "–∫–µ—Ä–∞–º–∏–∫–∞",
            "—Ä–µ–∑–∏–Ω–∞", "—Å–∏–ª–∏–∫–æ–Ω", "—Ç–µ–∫—Å—Ç–∏–ª—å", "–∫–æ–∂–∞", "–º–µ—Ç–∞–ª–ª",
            
            # –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            "–≥–∞—Ä–∞–Ω—Ç–∏—è", "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å", "–º–æ–¥–µ–ª—å", "–∞—Ä—Ç–∏–∫—É–ª", "—Å–µ—Ä–∏—è",
            "–ø–∞—Ä—Ç–∏—è", "—Å–±–æ—Ä–∫–∞", "–∫–∞—á–µ—Å—Ç–≤–æ", "—Å—Ç–∞–Ω–¥–∞—Ä—Ç", "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç"
        }
        self.logger.info("‚úÖ –°–æ–∑–¥–∞–Ω —Å–ø–∏—Å–æ–∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
    def get_synonym(self, word: str, context: str = "", pos: str = "") -> Optional[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–∞ –¥–ª—è —Å–ª–æ–≤–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Args:
            word: –°–ª–æ–≤–æ –¥–ª—è –∑–∞–º–µ–Ω—ã
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            pos: –ß–∞—Å—Ç—å —Ä–µ—á–∏ —Å–ª–æ–≤–∞
            
        Returns:
            str: –°–∏–Ω–æ–Ω–∏–º –∏–ª–∏ None –µ—Å–ª–∏ –∑–∞–º–µ–Ω–∞ –Ω–µ –Ω—É–∂–Ω–∞
        """
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –ø–æ–∏—Å–∫–∞
        word_lower = word.lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        if self._is_technical_term(word_lower, context):
            return None
        
        # –ü–æ–∏—Å–∫ –≤ —Å–ª–æ–≤–∞—Ä–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
        if word_lower in self.synonym_dict:
            synonyms = self.synonym_dict[word_lower]
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            filtered_synonyms = self._filter_by_context(synonyms, context, pos)
            
            if filtered_synonyms:
                import random
                return random.choice(filtered_synonyms)
            elif synonyms:
                import random
                return random.choice(synonyms)
        
        return None
    
    def _is_technical_term(self, word: str, context: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ç–µ—Ä–º–∏–Ω–æ–º"""
        # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if word in self.technical_terms:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º (—á–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è)
        technical_patterns = [
            r'\d+[.,]?\d*\s*(–º–º|—Å–º|–º|–∫–≥|–≥|–ª|–º–ª|–í—Ç|–∫–í—Ç|–í|–ê|–ì—Ü)',
            r'\b(–¥–∏–∞–º–µ—Ç—Ä|–¥–ª–∏–Ω–∞|—à–∏—Ä–∏–Ω–∞|–≤—ã—Å–æ—Ç–∞|–≤–µ—Å|–º–æ—â–Ω–æ—Å—Ç—å)\b',
            r'\b(–º–æ–¥–µ–ª—å|–∞—Ä—Ç–∏–∫—É–ª|—Å–µ—Ä–∏—è|–≥–∞—Ä–∞–Ω—Ç–∏—è)\b'
        ]
        
        for pattern in technical_patterns:
            if re.search(pattern, f"{word} {context}", re.IGNORECASE):
                return True
        
        return False
    
    def _filter_by_context(self, synonyms: List[str], context: str, pos: str) -> List[str]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∏ —á–∞—Å—Ç–∏ —Ä–µ—á–∏"""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—É—é –ª–æ–≥–∏–∫—É —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ —Å–∏–Ω–æ–Ω–∏–º—ã
        return synonyms
    
    def add_synonym(self, word: str, synonym: str):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–∞ –≤ —Å–ª–æ–≤–∞—Ä—å"""
        word_lower = word.lower()
        
        if word_lower not in self.synonym_dict:
            self.synonym_dict[word_lower] = []
        
        if synonym not in self.synonym_dict[word_lower]:
            self.synonym_dict[word_lower].append(synonym)
            self.logger.debug(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å–∏–Ω–æ–Ω–∏–º: {word} -> {synonym}")
    
    def add_technical_term(self, term: str):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞"""
        self.technical_terms.add(term.lower())
        self.logger.debug(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ç–µ—Ä–º–∏–Ω: {term}")
    
    def save_dictionaries(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π –≤ —Ñ–∞–π–ª—ã"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            self.dictionaries_path.mkdir(parents=True, exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
            general_path = self.dictionaries_path / "general_synonyms.json"
            with open(general_path, 'w', encoding='utf-8') as f:
                json.dump(self.synonym_dict, f, indent=2, ensure_ascii=False)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
            technical_path = self.dictionaries_path / "technical_terms.json"
            technical_data = {
                "preserved_terms": list(self.technical_terms),
                "metadata": {
                    "total_terms": len(self.technical_terms),
                    "updated_at": "auto_generated"
                }
            }
            with open(technical_path, 'w', encoding='utf-8') as f:
                json.dump(technical_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info("üíæ –°–ª–æ–≤–∞—Ä–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä–µ–π: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–ª–æ–≤–∞—Ä–µ–π"""
        return {
            "synonym_entries": len(self.synonym_dict),
            "total_synonyms": sum(len(synonyms) for synonyms in self.synonym_dict.values()),
            "technical_terms": len(self.technical_terms),
            "average_synonyms_per_word": sum(len(synonyms) for synonyms in self.synonym_dict.values()) / max(1, len(self.synonym_dict))
        }
