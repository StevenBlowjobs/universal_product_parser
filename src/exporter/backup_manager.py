#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
"""

import shutil
import zipfile
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any

from ..utils.logger import setup_logger
from ..utils.error_handler import retry_on_failure


class BackupManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, backup_dir: str = "data/backups"):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.logger = setup_logger("backup_manager")
        
        self.backup_settings = {
            'max_backups': 30,  # –ú–∞–∫—Å–∏–º—É–º 30 –±—ç–∫–∞–ø–æ–≤
            'backup_interval_hours': 24,  # –†–∞–∑ –≤ —Å—É—Ç–∫–∏
            'compress_backups': True,
            'include_logs': True,
            'include_configs': True
        }
    
    @retry_on_failure(max_retries=2)
    def create_backup(self, 
                     data_files: List[str] = None,
                     backup_name: str = None,
                     description: str = "") -> str:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        
        Args:
            data_files: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –±—ç–∫–∞–ø–∞
            backup_name: –ò–º—è –±—ç–∫–∞–ø–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            description: –û–ø–∏—Å–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞
            
        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –±—ç–∫–∞–ø—É
        """
        self.logger.info("üíæ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
        
        try:
            if not backup_name:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_name = f"backup_{timestamp}"
            
            backup_path = self.backup_dir / backup_name
            
            if self.backup_settings['compress_backups']:
                backup_path = backup_path.with_suffix('.zip')
                self._create_compressed_backup(backup_path, data_files, description)
            else:
                backup_path.mkdir(parents=True, exist_ok=True)
                self._create_directory_backup(backup_path, data_files, description)
            
            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
            self._cleanup_old_backups()
            
            self.logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
            return str(backup_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
            raise
    
    def _create_compressed_backup(self, backup_path: Path, data_files: List[str], description: str):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∂–∞—Ç–æ–≥–æ –±—ç–∫–∞–ø–∞"""
        with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            if data_files:
                for file_pattern in data_files:
                    for file_path in Path('data').rglob(file_pattern):
                        if file_path.is_file():
                            arcname = file_path.relative_to('data')
                            zipf.write(file_path, arcname)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥–æ–≤
            if self.backup_settings['include_logs']:
                for log_file in Path('data/output/logs').rglob('*.log'):
                    if log_file.is_file():
                        arcname = log_file.relative_to('data')
                        zipf.write(log_file, arcname)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥–æ–≤
            if self.backup_settings['include_configs']:
                for config_file in Path('config').rglob('*'):
                    if config_file.is_file():
                        arcname = config_file.relative_to('.')
                        zipf.write(config_file, arcname)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata = {
                'backup_date': datetime.now().isoformat(),
                'description': description,
                'files_included': len(zipf.filelist),
                'backup_size': backup_path.stat().st_size if backup_path.exists() else 0
            }
            
            zipf.writestr('backup_metadata.json', 
                         json.dumps(metadata, ensure_ascii=False, indent=2))
    
    def _create_directory_backup(self, backup_path: Path, data_files: List[str], description: str):
        """–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        if data_files:
            for file_pattern in data_files:
                for file_path in Path('data').rglob(file_pattern):
                    if file_path.is_file():
                        relative_path = file_path.relative_to('data')
                        target_path = backup_path / relative_path
                        target_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(file_path, target_path)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = {
            'backup_date': datetime.now().isoformat(),
            'description': description,
            'backup_type': 'directory'
        }
        
        with open(backup_path / 'backup_metadata.json', 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    def _cleanup_old_backups(self):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
        try:
            backups = []
            
            # –°–±–æ—Ä –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤
            for backup_file in self.backup_dir.iterdir():
                if backup_file.is_file() and backup_file.suffix in ['.zip', '']:
                    creation_time = datetime.fromtimestamp(backup_file.stat().st_ctime)
                    backups.append((backup_file, creation_time))
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
            backups.sort(key=lambda x: x[1], reverse=True)
            
            # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
            if len(backups) > self.backup_settings['max_backups']:
                for backup_file, _ in backups[self.backup_settings['max_backups']:]:
                    try:
                        if backup_file.is_file():
                            backup_file.unlink()
                        else:
                            shutil.rmtree(backup_file)
                        self.logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {backup_file}")
                    except Exception as e:
                        self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –±—ç–∫–∞–ø {backup_file}: {e}")
                        
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –±—ç–∫–∞–ø–æ–≤: {e}")
    
    def list_backups(self) -> List[Dict[str, Any]]:
        """
        –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤
        
        Returns:
            List[Dict]: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±—ç–∫–∞–ø–∞—Ö
        """
        backups_info = []
        
        for backup_file in self.backup_dir.iterdir():
            if backup_file.is_file() and backup_file.suffix == '.zip':
                try:
                    with zipfile.ZipFile(backup_file, 'r') as zipf:
                        metadata_str = zipf.read('backup_metadata.json').decode('utf-8')
                        metadata = json.loads(metadata_str)
                        
                        backups_info.append({
                            'name': backup_file.stem,
                            'path': str(backup_file),
                            'date': metadata.get('backup_date'),
                            'description': metadata.get('description', ''),
                            'size': backup_file.stat().st_size,
                            'file_count': metadata.get('files_included', 0)
                        })
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±—ç–∫–∞–ø–∞ {backup_file}: {e}")
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        backups_info.sort(key=lambda x: x.get('date', ''), reverse=True)
        
        return backups_info
    
    def restore_backup(self, backup_name: str, target_dir: str = "data") -> bool:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –±—ç–∫–∞–ø–∞
        
        Args:
            backup_name: –ò–º—è –±—ç–∫–∞–ø–∞
            target_dir: –¶–µ–ª–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        """
        self.logger.info(f"üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –±—ç–∫–∞–ø–∞: {backup_name}")
        
        try:
            backup_path = self.backup_dir / f"{backup_name}.zip"
            
            if not backup_path.exists():
                self.logger.error(f"‚ùå –ë—ç–∫–∞–ø –Ω–µ –Ω–∞–π–¥–µ–Ω: {backup_path}")
                return False
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
            temp_dir = Path('data/temp/restore')
            temp_dir.mkdir(parents=True, exist_ok=True)
            
            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –±—ç–∫–∞–ø–∞
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                zipf.extractall(temp_dir)
            
            # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –≤ —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            target_path = Path(target_dir)
            for file_path in temp_dir.rglob('*'):
                if file_path.is_file():
                    relative_path = file_path.relative_to(temp_dir)
                    final_path = target_path / relative_path
                    final_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(file_path, final_path)
            
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            shutil.rmtree(temp_dir)
            
            self.logger.info(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {backup_name} -> {target_dir}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
            return False
    
    def get_backup_stats(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±—ç–∫–∞–ø–æ–≤
        
        Returns:
            Dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±—ç–∫–∞–ø–æ–≤
        """
        backups = self.list_backups()
        
        total_size = sum(backup['size'] for backup in backups)
        total_files = sum(backup['file_count'] for backup in backups)
        
        return {
            'total_backups': len(backups),
            'total_size_bytes': total_size,
            'total_size_mb': total_size / (1024 * 1024),
            'total_files': total_files,
            'oldest_backup': backups[-1]['date'] if backups else None,
            'newest_backup': backups[0]['date'] if backups else None
        }


# –î–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –º–µ—Ç–æ–¥–∞—Ö –±—ç–∫–∞–ø–∞
import json
